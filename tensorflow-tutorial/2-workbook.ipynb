{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workbook 2: Computer Vision Neural Networks\n",
    "\n",
    "\n",
    "This notebook contains practice exercises on developing TensorFlow neural network models for computer vision tasks\n",
    "\n",
    "Solutions for this workbook can be found [here](./2-workbook-solutions.ipynb)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in `os`, `numpy`, `tensorflow`, `maplotlib`, and `scikit-learn` packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Developing an image classification neural network for the CIFAR10 dataset\n",
    "\n",
    "During this exercise you walk through the basic machine learning workflow in creating an image classification neural network to apply to the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Load the data\n",
    "\n",
    "Load in the CIFAR10 dataset (see [this Wiki](https://en.wikipedia.org/wiki/CIFAR-10) for more info on the dataset) using the built-in TensorFlow datasets *tf.keras.datasets* (view [the docs](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to see all readily available datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Inspect the data\n",
    "\n",
    "#### Exercise 1.2.1\n",
    "\n",
    "Find the shape and datatype of this data and use these values to answer the questions that follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Double click this cell to edit and add in your answers)\n",
    "\n",
    "##### Question 1. How many training samples are in this dataset?\n",
    "\n",
    "Answer:\n",
    "\n",
    "##### Question 2. How many testing samples are in this dataset?\n",
    "\n",
    "Answer:\n",
    "\n",
    "##### Question 3. What is the shape of the images we want to classify? Are these color images or black and white images?\n",
    "\n",
    "Answer:\n",
    "\n",
    "##### Questions 4. How are the images in the training and testing datasets labeled? Will we be required to One-Hot encode the labels?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.2\n",
    "\n",
    "Find some statistical information for our images including the minimum, maximum, and mean. Use this info to answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Double click this cell to edit and add in your answers)\n",
    "\n",
    "##### Question 1. What is the minimum and maximum pixel values of the images in the dataset?\n",
    "\n",
    "Answer:\n",
    "\n",
    "##### Question 2. Should we preprocess these images? Why or why not?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.3\n",
    "\n",
    "Calculate how many unique classes of images are in this dataset. *Hint: count how many different numbers occur in the image labels*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.4\n",
    "\n",
    "Plot a handful of images. What do the objects in these images appear to be? What classes might you assign these images? Try to find images from at least three different classes.\n",
    "\n",
    "*Note: these images will appear grainy and very low quality because they are. A typical image on your phone will be around the size 2000x1000x3 (i.e., 2000 pixels tall and 1000 pixels wide), but these images only have 32 pixels in height and width making them of significantly lower resolution.*\n",
    "\n",
    "*Note 2: the input **cmap='gray'** to the plot command **imshow** can be removed as we have color images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of the classes in the dataset include: Frogs, Cats, Planes, and Boats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.5\n",
    "\n",
    "If you determined that we should preprocess the images in Exercise 1.2.2, perform a unitization preprocessing on both the train and testing images and then calculate the minimum and maximum of the preprocessed data to check your preprocessing worked as expected. *Note: if you preprocess, do not forget to convert the image datasets to **float32** first*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.6\n",
    "\n",
    "If you determined that we need to reexpress the image lables into a One-Hot probability vector, perform that conversion. *Recall that **tf.one_hot** expects a 1d array of numbers as input and right now the labels are 2d arrays and you will need to remove any dimensions of size 1, which you can do by indexing or using **np.squeeze*** \n",
    "\n",
    "Print the first 3 labels in the train and test label datasets before you convert and after you convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.7\n",
    "\n",
    "Split the data into a training, testing, and validataion subsets. Use the same number of data samples for the testing and validation datasets. Calculate the shapes of the training, testing, and validataion sets to ensure they have the number of samples you are expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.8\n",
    "\n",
    "Create a TensorFlow Sequential model (either a Dense network or Convolutional network your choice) to classify the input CIFAR10 images into the 10 categories. Compile and build your model. You are welcome to use any appropriate loss function or optimizer. I would recommend using the 'accuracy' metric, you can however add additional metrics if you so wish.\n",
    "\n",
    "*Note: If you use convolutional layers the layer **tf.keras.layers.Reshape** used in the lesson is no longer necessary because our input images already have the final color channel axis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.9\n",
    "\n",
    "Build and display a summary of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.10\n",
    "\n",
    "Train your model using *model.fit*. If you wish to save the model weights from your training use the \"Create folder where we will save the training results\" code from the lesson and use the same callbacks from the lesson. You can choose the batch size and number of epochs. Use the training history returned by *model.fit* to plot the training and validataion losses and accuracy.\n",
    "\n",
    "*Note it is likely you will not see anywhere near as nice accuracy scores on this dataset compared to what was shown in the lesson. This is because the MNIST dataset from the lesson is a very easy image dataset to pickup patterns from compared to this CIFAR10 dataset. You may need to use many more epochs that what was used in the lesson as well.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.11\n",
    "\n",
    "Test your model using *model.evaluate*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1.2.12\n",
    "\n",
    "Tune your model by creating, training, and testing at least 3 variations on your origin model. As reminder things you can change include\n",
    "1. Hidden layer sizes\n",
    "2. Number of layers\n",
    "3. Type of layers\n",
    "4. Loss function\n",
    "5. Optimizer\n",
    "\n",
    "You can use the function *train_and_test* from the file *train_img_classification_net.py* as was done in the lesson. However, you may need to edit the file *train_img_classification_net.py* if you wish to change the loss function or optimizer.\n",
    "\n",
    "Which of your models performs the best? Why do you think that particular model performed the best for you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
